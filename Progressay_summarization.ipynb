{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "auoIunbEusBI"
      },
      "source": [
        "## Text Summarization Using Langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1l3nRCi9usBP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "open_api_key=\"sk-proj-QpkpUYCdV0cYlWkd6Ii5T3BlbkFJxqkoAoAiIwlgURWNw6Fn\"\n",
        "os.environ[\"OPENAI_API_KEY\"]=open_api_key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xe7vWIHkusBT",
        "outputId": "7824ff3c-1175-4a89-c893-6035cc1a20d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.2.0-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.9.5)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.6.6)\n",
            "Requirement already satisfied: langchain<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.2.0)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.2.1)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.1.60)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.25.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (8.3.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.21.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.0->langchain_community) (0.2.0)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.0->langchain_community) (2.7.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain_community) (23.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (3.10.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2024.2.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (4.11.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain_community) (2.4)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.0->langchain_community) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.0->langchain_community) (2.18.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
            "Installing collected packages: langchain_community\n",
            "Successfully installed langchain_community-0.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain\n",
        "!pip install langchain_community\n",
        "!pip install openai\n",
        "!pip install tiktoken\n",
        "## Basic Prompt Summarization\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema import(\n",
        "    AIMessage,\n",
        "    HumanMessage,\n",
        "    SystemMessage\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "og1Hs4TKusBU"
      },
      "outputs": [],
      "source": [
        "speech=\"\"\"\n",
        "People across the country, involved in government, political, and social activities, are dedicating their time to make the ‘Viksit Bharat Sankalp Yatra’ (Developed India Resolution Journey) successful. Therefore, as a Member of Parliament, it was my responsibility to also contribute my time to this program. So, today, I have come here just as a Member of Parliament and your ‘sevak’, ready to participate in this program, much like you.\n",
        "\n",
        "In our country, governments have come and gone, numerous schemes have been formulated, discussions have taken place, and big promises have been made. However, my experience and observations led me to believe that the most critical aspect that requires attention is ensuring that the government’s plans reach the intended beneficiaries without any hassles. If there is a ‘Pradhan Mantri Awas Yojana’ (Prime Minister’s housing scheme), then those who are living in jhuggis and slums should get their houses. And he should not need to make rounds of the government offices for this purpose. The government should reach him. Since you have assigned this responsibility to me, about four crore families have got their ‘pucca’ houses. However, I have encountered cases where someone is left out of the government benefits. Therefore, I have decided to tour the country again, to listen to people’s experiences with government schemes, to understand whether they received the intended benefits, and to ensure that the programs are reaching everyone as planned without paying any bribes. We will get the real picture if we visit them again. Therefore, this ‘Viksit Bharat Sankalp Yatra’ is, in a way, my own examination. I want to hear from you and the people across the country whether what I envisioned and the work I have been doing aligns with reality and whether it has reached those for whom it was meant.\n",
        "\n",
        "It is crucial to check whether the work that was supposed to happen has indeed taken place. I recently met some individuals who utilized the Ayushman card to get treatment for serious illnesses. One person met with a severe accident, and after using the card, he could afford the necessary operation, and now he is recovering well. When I asked him, he said: “How could I afford this treatment? Now that there is the Ayushman card, I mustered courage and underwent an operation. Now I am perfectly fine.”  Such stories are blessings to me.\n",
        "\n",
        "The bureaucrats, who prepare good schemes, expedite the paperwork and even allocate funds, also feel satisfied that 50 or 100 people who were supposed to get the funds have got it. The funds meant for a thousand villages have been released. But their job satisfaction peaks when they hear that their work has directly impacted someone’s life positively. When they see the tangible results of their efforts, their enthusiasm multiplies. They feel satisfied. Therefore, ‘Viksit Bharat Sankalp Yatra’ has had a positive impact on government officers. It has made them more enthusiastic about their work, especially when they witness the tangible benefits reaching the people. Officers now feel satisfied with their work, saying, “I made a good plan, I created a file, and the intended beneficiaries received the benefits.” When they find that the money has reached a poor widow under the Jeevan Jyoti scheme and it was a great help to her during her crisis, they realise that they have done a good job. When a government officer listens to such stories, he feels very satisfied.\n",
        "\n",
        "There are very few who understand the power and impact of the ‘Viksit Bharat Sankalp Yatra’. When I hear people connected to bureaucratic circles talking about it, expressing their satisfaction, it resonates with me. I’ve heard stories where someone suddenly received 2 lakh rupees after the death of her husband, and a sister mentioned how the arrival of gas in her home transformed her lives. The most significant aspect is when someone says that the line between rich and poor has vanished. While the slogan ‘Garibi Hatao’ (Remove Poverty) is one thing, but the real change happens when a person says, “As soon as the gas stove came to my house, the distinction between poverty and affluence disappeared.\n",
        "\"\"\"\n",
        "\n",
        "# speech=\"\"\"بلا شک، چلیں، گازا کے مختلف پہلوؤں کو مزید گہرائی سے جانیں:\n",
        "\n",
        "# جغرافیائی طور پر، گازا ایک چھوٹا علاقہ ہے جو میڈیٹرینیئن سمندر کی مشرقی ساحل پر واقع ہے۔ اس کی شرق اور شمال میں اسرائیل اور جنوب میں مصر کے ساتھ سرحدوں پر ہے۔ دو ملین سے زائد آبادی والے اس علاقے میں دنیا کے سب سے زیادہ آبادی والے علاقوں میں سے ایک ہے۔ گازا کی تاریخ ایک پیچیدہ تاریخ سے گزری ہے جس میں اسرائیل اور فلسطینی دہشت گرد گروپس جیسے حماس کے درمیان جھگڑوں کا بھرپور تاریخی حصہ ہے۔ اس خطے کو انسانیتی معاملات کا سامنا ہے، جو رہائی کی پابندیوں، بنیادی خدمات تک رسائی محدود ہونے، اور وقتا وقتا کی فوجی کارروائیوں کی وجہ سے اس کے رہائشیوں کے لیے نہایت مشکلات پیدا کرتا ہے۔\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wpJIpSdbusBW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98bf41b0-d222-495d-d722-4d8872536842"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ],
      "source": [
        "chat_messages=[\n",
        "    SystemMessage(content='You are an expert assistant with expertize in summarizing speeches'),\n",
        "    HumanMessage(content=f'Please provide a short and concise summary of the following speech:\\n TEXT: {speech}')\n",
        "]\n",
        "\n",
        "llm=ChatOpenAI(model_name='gpt-3.5-turbo')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVSpUyn-usBY",
        "outputId": "b74c1ad7-e301-4424-c667-52a7b34889e3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "866"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "##total tokens\n",
        "llm.get_num_tokens(speech)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "id": "VVwEioFMusBd",
        "outputId": "bbe04dc9-e6a6-4dc2-ebe5-633a771df4ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Summary:\\nThe speech highlights the importance of ensuring government schemes reach intended beneficiaries smoothly, without the need for bribes. The speaker, a Member of Parliament, shares experiences of people benefiting from schemes like 'Pradhan Mantri Awas Yojana' and 'Ayushman card'. The 'Viksit Bharat Sankalp Yatra' aims to assess the impact of government programs by interacting with citizens and government officers. The journey has boosted officers' morale as they witness firsthand the positive impact of their work on people's lives. The speech underscores the transformative power of effective implementation of government schemes in bridging the gap between rich and poor.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "llm(chat_messages).content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2AAk_onLusBg",
        "outputId": "40ccf0ab-ba33-4e25-b5dc-4173a35907ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary:\n",
            "The speaker, a Member of Parliament, emphasizes the importance of ensuring government schemes reach intended beneficiaries without hurdles. They have personally witnessed positive impacts, such as individuals benefiting from the Ayushman card for medical treatment. The speaker highlights the satisfaction felt by bureaucrats when they see tangible results of their work positively impacting people's lives. The 'Viksit Bharat Sankalp Yatra' aims to assess the effectiveness of government programs by interacting with the public to ensure the schemes are reaching everyone as intended. The journey has inspired enthusiasm and job satisfaction among government officers as they witness the direct benefits of their efforts. The ultimate goal is to bridge the gap between rich and poor through effective implementation of welfare schemes.\n"
          ]
        }
      ],
      "source": [
        "##get_summary\n",
        "print(llm(chat_messages).content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpvKE9IGusBi"
      },
      "source": [
        "## Prompt Templates Text Summarization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yW7iPAMvusBk"
      },
      "outputs": [],
      "source": [
        "\n",
        "from langchain.chains import LLMChain\n",
        "from langchain import PromptTemplate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "giYTds4ousBm"
      },
      "outputs": [],
      "source": [
        "generic_template='''\n",
        "Write a summary of the following speech:\n",
        "Speech : `{speech}`\n",
        "Translate the precise summary to {language}.\n",
        "\n",
        "'''\n",
        "prompt=PromptTemplate(\n",
        "    input_variables=['speech','language'],\n",
        "    template=generic_template\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "fEA_Ft7tusBn",
        "outputId": "034c0a34-0192-4955-b9c2-7db0961e2d2d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nWrite a summary of the following speech:\\nSpeech : `\\nPeople across the country, involved in government, political, and social activities, are dedicating their time to make the ‘Viksit Bharat Sankalp Yatra’ (Developed India Resolution Journey) successful. Therefore, as a Member of Parliament, it was my responsibility to also contribute my time to this program. So, today, I have come here just as a Member of Parliament and your ‘sevak’, ready to participate in this program, much like you.\\n\\nIn our country, governments have come and gone, numerous schemes have been formulated, discussions have taken place, and big promises have been made. However, my experience and observations led me to believe that the most critical aspect that requires attention is ensuring that the government’s plans reach the intended beneficiaries without any hassles. If there is a ‘Pradhan Mantri Awas Yojana’ (Prime Minister’s housing scheme), then those who are living in jhuggis and slums should get their houses. And he should not need to make rounds of the government offices for this purpose. The government should reach him. Since you have assigned this responsibility to me, about four crore families have got their ‘pucca’ houses. However, I have encountered cases where someone is left out of the government benefits. Therefore, I have decided to tour the country again, to listen to people’s experiences with government schemes, to understand whether they received the intended benefits, and to ensure that the programs are reaching everyone as planned without paying any bribes. We will get the real picture if we visit them again. Therefore, this ‘Viksit Bharat Sankalp Yatra’ is, in a way, my own examination. I want to hear from you and the people across the country whether what I envisioned and the work I have been doing aligns with reality and whether it has reached those for whom it was meant.\\n\\nIt is crucial to check whether the work that was supposed to happen has indeed taken place. I recently met some individuals who utilized the Ayushman card to get treatment for serious illnesses. One person met with a severe accident, and after using the card, he could afford the necessary operation, and now he is recovering well. When I asked him, he said: “How could I afford this treatment? Now that there is the Ayushman card, I mustered courage and underwent an operation. Now I am perfectly fine.”  Such stories are blessings to me.\\n\\nThe bureaucrats, who prepare good schemes, expedite the paperwork and even allocate funds, also feel satisfied that 50 or 100 people who were supposed to get the funds have got it. The funds meant for a thousand villages have been released. But their job satisfaction peaks when they hear that their work has directly impacted someone’s life positively. When they see the tangible results of their efforts, their enthusiasm multiplies. They feel satisfied. Therefore, ‘Viksit Bharat Sankalp Yatra’ has had a positive impact on government officers. It has made them more enthusiastic about their work, especially when they witness the tangible benefits reaching the people. Officers now feel satisfied with their work, saying, “I made a good plan, I created a file, and the intended beneficiaries received the benefits.” When they find that the money has reached a poor widow under the Jeevan Jyoti scheme and it was a great help to her during her crisis, they realise that they have done a good job. When a government officer listens to such stories, he feels very satisfied.\\n\\nThere are very few who understand the power and impact of the ‘Viksit Bharat Sankalp Yatra’. When I hear people connected to bureaucratic circles talking about it, expressing their satisfaction, it resonates with me. I’ve heard stories where someone suddenly received 2 lakh rupees after the death of her husband, and a sister mentioned how the arrival of gas in her home transformed her lives. The most significant aspect is when someone says that the line between rich and poor has vanished. While the slogan ‘Garibi Hatao’ (Remove Poverty) is one thing, but the real change happens when a person says, “As soon as the gas stove came to my house, the distinction between poverty and affluence disappeared.\\n`\\nTranslate the precise summary to Urdu.\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "prompt.format(speech=speech,language='Urdu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UgspNwWIusBp"
      },
      "outputs": [],
      "source": [
        "complete_prompt=prompt.format(speech=speech,language='urdu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAwdu_pqusBq",
        "outputId": "e22359a3-84ba-46a0-e5fb-ded9e52fdf1c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "886"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "llm.get_num_tokens(complete_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2TvPLsr8usBq"
      },
      "outputs": [],
      "source": [
        "llm_chain=LLMChain(llm=llm,prompt=prompt)\n",
        "summary=llm_chain.run({'speech':speech,'language':'English'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "ofxyERlDusBr",
        "outputId": "c16c83ce-3fa8-435c-cf19-ba3eb55d003d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'اس سپیچ کا صرف مقصد ہے کہ حکومت کے منصوبوں کو درست مقصدوں تک پہنچایا جائے، بغیر کسی رشوت دینے کے۔ اس کے لیے میرے پاس دوبارہ ملک کا دورہ کرنے کا فیصلہ ہے تاکہ میں لوگوں کی تجربات سن سکوں اور یہ جان سکوں کہ کیا میں نے جو کچھ سوچا تھا اور جو کام کیا ہے، وہ حقیقت میں بھی ہوا ہے یا نہیں۔ اسی لیے \\'وکسیت بھارت سنکلپ یاترا\\' میرا اپنا امتحان ہے۔ میں اپ کی سننا چاہتا ہوں کہ کیا میرا ویژن اور میرا کام وہ لوگوں تک پہنچا ہے جن کے لیے یہ منصوبہ بنایا گیا تھا۔\\n\\nحکام، جو اچھے منصوبے تیار کرتے ہیں، کاغذات کی تیزی سے تیاری کرتے ہیں اور فنڈز کی تفویض بھی کرتے ہیں، وہ اس بات سے مطمئن ہوتے ہیں کہ پچاس یا سو لوگ جن کو فنڈز ملنے تھے، وہ انہیں مل گئے ہیں۔ ان کی کام کی تسلی اس وقت بڑھتی ہے جب وہ دیکھتے ہیں کہ ان کی محنت کے نتائج کسی کے زندگی میں مثبت طور پر اثر ڈال رہے ہیں۔ وقت کے ساتھ حکومتی افسران اپنے کام سے زیادہ محسوس کرتے ہیں، کچھ افسران کو احساس ہے کہ انہوں نے اچھا منصوبہ بنایا، ایک فائل تیار کی اور مقصد کو پہنچایا گیا۔ جب انہوں نے دیکھا کہ رقم ایک غریب بیوہ کے پاس پہنچ گئی ہے اور یہ اس کی مدد کرتی ہے، تو انہوں نے محسوس کیا کہ انہوں نے اچھا کام کیا ہے۔\\n\\nوکسیت بھارت سنکلپ یاترا نے حکومتی افسران پر مثبت اثر ڈالا ہے اور انہیں ان کے کام کے لیے زیادہ بے قواس بنا دیا ہے، خاص طور پر جب انہوں نے دیکھا کہ حقیقی فوائد لوگوں تک پہنچ رہے ہیں۔ افسران اب اپنے کام سے مطمئن ہوتے ہیں، کہتے ہیں، \"میں نے ایک اچھا منصوبہ بنایا، میں نے ایک فائل تیار کی، اور مقصد کو پہنچایا گیا ہے۔\" جب ایک حکومتی افسر ایسی کہانیوں کو سنتا ہے، تو وہ بہت مطمئن محسوس کرتا ہے۔'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "summary"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "qhD3Glc0PvnS",
        "outputId": "e50441f8-fb0c-4480-cd0e-1892fa634c19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"The speaker discusses their involvement in the 'Viksit Bharat Sankalp Yatra' program, aimed at ensuring government schemes reach intended beneficiaries without any hassles. They share examples of individuals benefiting from schemes like the Ayushman card and emphasize the satisfaction felt by bureaucrats when they see tangible results of their work positively impacting people's lives. The speaker highlights the positive impact of the program on government officers, who feel more enthusiastic about their work when they witness the benefits reaching the people. They also mention stories of individuals whose lives have been transformed by government schemes, emphasizing the importance of eliminating the distinction between rich and poor.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fD6UNMOWusBs"
      },
      "source": [
        "## StuffDocumentChain Text Summarization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bc_GwuvpusBs",
        "outputId": "fe463599-24f0-45f1-ce8c-bfa989c8df3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m174.1/232.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install PyPDF2\n",
        "from PyPDF2 import PdfReader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OsPjXu7SusBu"
      },
      "outputs": [],
      "source": [
        "# provide the path of  pdf file/files.\n",
        "pdfreader = PdfReader('/content/Data Scientist_Noman Rafique.pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "62V6VHkyusBu"
      },
      "outputs": [],
      "source": [
        "from typing_extensions import Concatenate\n",
        "# read text from pdf\n",
        "text = ''\n",
        "for i, page in enumerate(pdfreader.pages):\n",
        "    content = page.extract_text()\n",
        "    if content:\n",
        "        text += content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "Aj3BGf7WusBv",
        "outputId": "1681962d-9561-44fe-da16-dc844e23de1a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Address:  Lahore Pakistan  \\nPhone  : +92 346 0842762  \\nEmail:  naumanrafique10@gmail.com  \\nData  Scientist /  Machine  Learning  Engineer  Linked  In:linkedin.com/noman -rafique \\nSUMMARY  \\nAs an experienced Data Scientist with over 2 years of expertise, I specialize in building data -intensive applications, employing advanced \\ntechniques such as Stable Diffusion, Chatbots, Generative AI, LLM, Computer Vision, Natural Language Processing, and Time Ser ies \\nAnalysis. My proven track record of translating complex data into actionable insights underscores my commitment to driving bu siness \\nsuccess through innovative and impactful data science solutions . \\nWORK  EXPERIENCE  \\n \\nData  Scientist  Lahore  \\nProgrammers For ce Sep 2021  – Present  \\n Project: Generative AI  \\nChat  Bot for Medical  and Researchers  \\n• Developed  a cutting -edge  chat  bot utilizing  LangChain,Pinecone  technology,  catering  to the unique  needs  of \\nmedical  professionals  and researchers. The  chat bot facilitates file uploads and offers interactive query -based \\ninteractions.  \\n• Implemented  robust  file parsing  and query  processing  capabilities,  enabling  seamless  communication  between  users  and the \\nchat  bot. \\n• Designed  a user -friendly  interface  to enhance  data  accessibility  and analysis  for medical  practitioners  and researchers.  \\n• Demonstrated  expertise  in domain -specific  requirements  and language  processing,  revolutionizing  medical  and research  \\nworkflows.  \\nAI-Driven  HR Solutions  Trailblazer  Developed  \\n• Directed the strategic planning and execution of a sophisticated talent alignment platform, leveraging state -of-the-art AI \\ntechnologies  such as  LSTM, GPT -3, and Pinecone . \\n• Demonstrated  a remarkable  97%  accuracy  in predicting  department  using  LSTM  and providing  personalized  resume  \\nrecommendations,  aligned with the job description's specifications by leveraging LLM’s and Pinecone.  \\n Project: Natural Language Processing  \\nTwitter  Profile  & Tweet  Analysis  for Political  Inclination  Prediction  \\n• Conducted  topic  modelling  and sentiment  analysis on  Twitter  profiles  and tweets  to predict  the political \\npreferences  of users  based on  their  location, tweets and profile information.  \\n• Utilized advanced  NLP techniques to  extract  valuable  insights  from  Twitter  data,  such as  determining the  \\ndominant  topics  discussed  by users and analyzing their sentiment towards political candidates.  \\n• Developed strategies  to analyze  the relationships between user  profile  information,  and tweet  content  to \\naccurately  predict  their  candidate  preferences. Demonstrated proficiency in data analysis, machine learning, \\nand NLP, resulting in a successful project that provided valuable  insights into the political inclination of Twitter \\nusers . \\n \\n Project:  Computer  Vision  \\nAutomated  Quality  Control  in a Clothing Factory:  \\n• Engineered an advanced AI model, harnessing the precision of YOLO computer vision technology, to autonomously \\ndetect nuanced garment  defects.  \\n• Proficiently  identifies  intricate  imperfections,  encompassing  stitching  irregularities,  fabric  tears,  and missing  \\nbuttons,  within  real-time  production  processes.  \\n• My AI model epitomizes a cost -efficient and supremely effective solution, elevating the paradigm of quality control \\nin clothing manufacturing,  concurrently optimizing resource allocation, and elevating the overall product quality.  \\n \\nDetecting  Defects  in Production  & Maintenance  Department  in a Steel  Company  \\n• Implemented  Deep Learning  CNN  ResNet  and Mobilenet  models for  defect  detection  in the Production  & \\nMaintenance  Department  of a Steel  Company. Leveraged Transfer Learning techniques to utilize pre -trained \\nmodels for efficient training and improved accuracy.  \\n• Conducted extensive data preprocessing and augmentation to handle imbalanced data and enhance model \\nperformance. The combination of  ResNet and Mobilenet architectures allowed for accurate identification of \\ndefects in steel products, contributing to quality control and  maintenance  efficiency.  \\n• Successfully integrated the deep learning models into the company's production and maintenance processes, \\nfacilitating real -time defect  detection and supporting proactive maintenance strategies.  \\n Project:  Time  Series  Forecasting  \\nNoman  Rafique  Trajectory  Prediction  for Geo Spatial  using  Time  Series  Transformer  \\n• Leveraged  an IMU  dataset,  encompassing  accelerometer,  magnetometer,  and gyroscope  measurements  for \\nforecasting  human  trajectories  in geographic space, predicting altitude, longitude, and latitude with respect to time.  \\n• Demonstrated  remarkable  project  performance  with  a minimal loss rate  of 0.034  and a remarkable  99%  cosine  \\nsimilarity,  showcasing  exceptional  predictive accuracy and precision.  \\nStock  Price Prediction  \\n• Manage d and executed  a Stock  Price  Prediction  project  of 4 markets  of Saudi  Arabia,  utilizing  historical  stock  price  \\ndata  to accurately  forecast  monthly stock prices with a high level of precision.  \\n• Employed  various  time  series  forecasting  techniques,  such  as ARIMA, SARIMA  and Holt Winter  model  to analyze  \\nstock  price  patterns  and trends.  \\n• Conducted  thorough  data exploration  and preprocessing  to handle  seasonality,  trends,  and anomalies  in the footfall  \\ndata,  resulting in  reliable  and actionable  predictions.  \\nProject : Loan  Default  Risk  Assessment System  \\n•  Delivered a  classification  project  focused  on electric  pump  loans  provided  to farmers,  with  the objective  of \\naccurately  predicting  loan payers  and defaulters based on their pump usage patterns and got remarkable 98% \\naccuracy.  \\n•  Developed  and implemented a  robust  machine  learning  model,  employing  classification  algorithms  to predict  the \\nlikelihood  of loan repayment  by farmers.  \\n• Conducted  extensive data  preprocessing  and feature  engineering  to extract  relevant  pump  usage  metrics,  water  \\nconsumption  patterns,  and other crucial factors for accurate classification.  \\n•  Achieved an  exceptional  precision  rate of 95%  by analyzing  borrowers'  pump  usage  patterns,  effectively  \\ndistinguishing  between  loan payers  and defaulters. This outcome aligns perfectly with our project's focus on \\nprecision.  \\nProject : Project  Churn  Prediction  \\n• Designed  and implemented  a predictive Churn  Model  Python/Pandas/Pyspark,  to accurately  identify  and segment  \\nusers  with  varying  levels  of churn risk (Low, Medium, High).  \\n• Optimized the  model  to update  every  2 weeks  with  new  user  data,  providing  the marketing team  with \\nactionable  insights to  drive  targeted retention campaigns.  \\n• Integrated  the results  into a Tableau  Dashboard,  enabling  the Insights  Team  to make  data -driven  decisions  to improve  user  \\nretention.  \\nProject:  Alternate  Credit  Scoring  \\n• Led the groundbreaking  Alternate  Credit  Scoring  project, surpassing  expectations with  a remarkable  accuracy  \\nrate of 85%  in credit  assessment.  \\n• Distinguished  this project  through  its unique  selling  point  of not relying on  traditional  credit  history  data  during  model  \\ntraining.  \\n• Leveraged  data  from  a telecom  service  provider  to accurately assess  the creditworthiness  of users.  \\n• Engineered  robust  credit  score  cards  for users,  enabling  precise  risk categorization  into high  risk, medium  risk, and low risk \\ngroups.  \\n• Demonstrated  the potential  for advanced  analytics to  generate  reliable  credit  assessments,  even  in the absence  of \\nconventional  credit  history  data.  \\n• Executed  the project  as a pivotal  component  of the transformative  Analytics  as a Service  initiative,  delivering  \\nimpactful  insights  to optimize credit evaluation processes and  \\n Project:  Recommendation  System  \\nContent -Based  Recommendation  System  \\n• Designed  and implemented  a Content -Based  Recommendation  System  tailored  for job applicants,  presenting  them  \\nwith  personalized  company and job recommendations.  \\n• Utilized  advanced  natural  language  processing  (NLP)  techniques  to extract  key features  from  company  profiles  and job \\ndescriptions,  enabling accurate matching with applicants' preferences and qualifications.  \\nCollaborative -Based  Recommendation  System  \\n• Developed  a personalized  Book  Recommender System  using  collaborative  filtering  and content -based  \\nfiltering  techniques  to provide tailored book recommendations to users based on their interests and \\nreading history.  \\n• Conducted  data  preprocessing  and feature  engineering to  extract  relevant  book  features,  such  as genre,  author,  user  \\nratings,  and reading  history, for improved recommendation accuracy.  \\nSKILLS/Tools  \\n \\nProgramming  language  and Tools:  Psython,  R Programming,  C++,  Java,  SQL,NoSQL,  Matlab  \\nData  Science  and AI Techniques:  Supervised/  Semi -supervised/  Unsupervised  Learning,  Classification,  Clustering,  Regression,Anomaly \\nDetection,Predictive Analytics, Statistical Modelling ,Time Series, Machine Learning, Deep Learning, NLP,Computer Vision,MLOP s. \\nCloud  Platforms:  GCP,  AWS  \\nBusiness  Acumen : Aligning  ML initiatives  with  business  objectives  and understanding  of credit.  \\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I00XKiFIusBv"
      },
      "outputs": [],
      "source": [
        "from langchain.docstore.document import Document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lzf49EWFusBw"
      },
      "outputs": [],
      "source": [
        "docs = [Document(page_content=text)]\n",
        "docs[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qTrwXiCdusBw"
      },
      "outputs": [],
      "source": [
        "llm = ChatOpenAI(temperature=0, model_name='gpt-3.5-turbo')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pQ_mHXSEusBx"
      },
      "outputs": [],
      "source": [
        "from langchain import PromptTemplate\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains.summarize import load_summarize_chain\n",
        "from langchain.docstore.document import Document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ipyKLiCcusBx"
      },
      "outputs": [],
      "source": [
        "template = '''Write a concise and short summary of the following speech.\n",
        "Speech: `{text}`\n",
        "'''\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=['text'],\n",
        "    template=template\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7sUFU9-wusBy"
      },
      "outputs": [],
      "source": [
        "chain = load_summarize_chain(\n",
        "    llm,\n",
        "    chain_type='stuff',\n",
        "    prompt=prompt,\n",
        "    verbose=False\n",
        ")\n",
        "output_summary = chain.run(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sj9jwy6ousBy"
      },
      "outputs": [],
      "source": [
        "output_summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_mtAggYusBz"
      },
      "source": [
        "## Summarizing Large Documents Using Map Reduce"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pwJugumXusBz"
      },
      "outputs": [],
      "source": [
        "from langchain import PromptTemplate\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains.summarize import load_summarize_chain\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7CVTW84YusBz"
      },
      "outputs": [],
      "source": [
        "# provide the path of  pdf file/files.\n",
        "pdfreader = PdfReader('/content/Data Scientist_Noman Rafique.pdf')\n",
        "from typing_extensions import Concatenate\n",
        "# read text from pdf\n",
        "text = ''\n",
        "for i, page in enumerate(pdfreader.pages):\n",
        "    content = page.extract_text()\n",
        "    if content:\n",
        "        text += content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vZST13FAusB0"
      },
      "outputs": [],
      "source": [
        "llm = ChatOpenAI(temperature=0, model_name='gpt-3.5-turbo')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WG2vYVybusB0",
        "outputId": "b08a3dbc-847e-46fa-f504-bae04ce412ce"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2132"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "llm.get_num_tokens(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FLI27A9wusB1"
      },
      "outputs": [],
      "source": [
        "## Splittting the text\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=10000, chunk_overlap=20)\n",
        "chunks = text_splitter.create_documents([text])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKiiHVKnusB2",
        "outputId": "f8703c44-d7d7-4628-8be5-0133cac24749"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "len(chunks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RU8vCc9IusB2"
      },
      "outputs": [],
      "source": [
        "chain = load_summarize_chain(\n",
        "    llm,\n",
        "    chain_type='map_reduce',\n",
        "    verbose=False\n",
        ")\n",
        "summary = chain.run(chunks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "TgdfQgK3usB3",
        "outputId": "48fb35cf-5a5a-4f54-a0b9-ac71b057ef25"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Nauman Rafique is an experienced Data Scientist and Machine Learning Engineer based in Lahore, Pakistan, with expertise in building data-intensive applications using advanced techniques such as Stable Diffusion, Chatbots, Generative AI, Computer Vision, and Natural Language Processing. He has a proven track record of translating complex data into actionable insights for business success, working on projects including AI-driven HR solutions, Twitter sentiment analysis, automated quality control in clothing factories, and time series forecasting. Nauman's skills include programming languages such as Python and R, data science techniques, AI technologies, and experience in cloud platforms like GCP and AWS, with a strong business acumen in aligning ML initiatives with business objectives.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLzF1CHLusB3"
      },
      "source": [
        "## Map Reduce With Custom Prompts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nvIC2UtFusCC"
      },
      "outputs": [],
      "source": [
        "chunks_prompt=\"\"\"\n",
        "Please summarize the below speech:\n",
        "Speech:`{text}'\n",
        "Summary:\n",
        "\"\"\"\n",
        "map_prompt_template=PromptTemplate(input_variables=['text'],\n",
        "                                    template=chunks_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_nPANxqtusCC"
      },
      "outputs": [],
      "source": [
        "final_combine_prompt='''\n",
        "Provide a final summary of the entire speech with these important points.\n",
        "Add a Generic Motivational Title,\n",
        "Start the precise summary with an introduction and provide the\n",
        "summary in number points for the speech.\n",
        "Speech: `{text}`\n",
        "'''\n",
        "final_combine_prompt_template=PromptTemplate(input_variables=['text'],\n",
        "                                             template=final_combine_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VESPgAB7usCD"
      },
      "outputs": [],
      "source": [
        "summary_chain = load_summarize_chain(\n",
        "    llm=llm,\n",
        "    chain_type='map_reduce',\n",
        "    map_prompt=map_prompt_template,\n",
        "    combine_prompt=final_combine_prompt_template,\n",
        "    verbose=False\n",
        ")\n",
        "output = summary_chain.run(chunks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3TuHPqLusCD",
        "outputId": "4313a913-fa70-448c-e207-35eed9eba00c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Title: \"Empowering Success Through Data Science\"',\n",
              " '',\n",
              " 'Introduction:',\n",
              " 'The speaker, an experienced Data Scientist, shared insights on their expertise in building data-intensive applications using advanced techniques and successfully implementing projects in various domains.',\n",
              " '',\n",
              " 'Summary:',\n",
              " \"1. The speaker's expertise includes Stable Diffusion, Chatbots, Generative AI, Computer Vision, Natural Language Processing, and Time Series Analysis.\",\n",
              " '2. They have implemented projects in medical, HR solutions, political inclination prediction, quality control in clothing manufacturing, defect detection in steel products, trajectory prediction, stock price prediction, loan default risk assessment, churn prediction, alternate credit scoring, and recommendation systems.',\n",
              " '3. Possessing skills in programming languages, data science and AI techniques, cloud platforms, and business acumen, the speaker aligns ML initiatives with business objectives effectively. ',\n",
              " '',\n",
              " \"In conclusion, the speaker's diverse skill set and experience in data science showcase their ability to drive success through innovative applications and strategic alignment with business goals.\"]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "output.split(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45Ai2mYHusCD"
      },
      "source": [
        "**Rewrite/Rephrase the text**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "speech1=\"\"\"I hope you're doing great.\n",
        "\n",
        "Last time , I got shortlisted and you asked me for an interview but unfortunately I was not geer up for an interview and we cancelled the interview.\n",
        "\n",
        "Now, I'm fully gear up and interested in working with you. Could you please set up an interview for 2+ years of for Data Scientist/ML/AI Position.\"\"\"\n",
        "chat_messages1=[\n",
        "    SystemMessage(content='You are an expert assistant with expertize in assisting to user with speeches'),\n",
        "    HumanMessage(content=f'Please rewrite/rephrase in professional tone following speech:\\n TEXT: {speech1}')\n",
        "]\n",
        "\n",
        "llm=ChatOpenAI(model_name='gpt-3.5-turbo')\n",
        "##get_summary\n",
        "print(llm(chat_messages1).content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QkZ7jOp26Sw",
        "outputId": "6812ee8f-f3bb-44b2-d464-f402e6b88775"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I trust this message finds you well.\n",
            "\n",
            "During our previous correspondence, I was honored to have been shortlisted for an interview with your esteemed organization. Regrettably, at that time I was not fully prepared for the interview, leading to its cancellation.\n",
            "\n",
            "I am now fully equipped and eager to pursue the opportunity to work alongside your team. It would be greatly appreciated if you could schedule an interview for the position of Data Scientist/ML/AI, requiring a minimum of 2 years of experience.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9bpQ9O2OQc4j"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}